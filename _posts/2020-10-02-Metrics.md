---
layout: post
title: Metrics
date: 2020-10-02
author: Brad
tags:  Machine_Learning
comments: true
toc: true
pinned: false
---

*  分類預測
	* Tp→真正 True positive
	* Tn→真負 True negative
	* Fp→假正 False positive
	* Fn→假負 False negative
	
<!-- more -->

* 召回率、敏感度
    * ![](https://i.imgur.com/8ocLumV.png)
	* Accuracy=$\frac{Tp+Tn}{Tp+Tn+Fp+Fn}$
		* 可理解為系統的準確率
	* Precision=$\frac{Tp}{Tp+Fp}$
		* 可理解為在「預測為正」的結果中，真正為「正」的比例
		* 此數值越高，表示誤判率越低，追求此數值通常是使用者比較在意誤判
	* Recall=$\frac{Tp}{Tp+Fn}$
		* 可理解為在「實際為正」的結果中，真正為「正」的比例
	* F Measure=$F_\beta=(1+\beta^2)\times\frac{precision\times recall}{(\beta^2\times precision)+recall}$
		* 此為融合了precision和recall的平均數，並以β作為調整比例
			* 當β=1，即為F1 Score
				* F1 Score=$\frac{2}{\frac{1}{precision}+\frac{1}{recall}}=2\times \frac{precision\times recall}{precision+recall}$
			* β為precision的加權，越小代表越看重precision
	* 例子
		* 在癌症預測中，假設罹癌的比例為1%，如果一系統預測100%預測沒有癌症，那1000人中
			* FN=1、TN=999，在accuracy會很高，可是recall和precision會為零→此系統無效
			* 所以有時候會不惜提高FP，以換來盡量少的FN
		* 在垃圾郵件中，人們很難接受FP(只要有一封重要郵件被視為垃圾)
			* 通常會適度降低recall，以提高precision
	* 延伸
		* ROC曲線(Receiver Operating characteristic Curve)
			* 橫坐標為 false positive rate (FPR)，縱坐標為 true positive rate (TPR)
			* TPR=$\frac{Tp}{Fp+Fn}$   ,  FPT=$\frac{Fp}{Fp+Tn}$
			* AUC值(Area Under Curve)：ROC曲線下的面積，取 0.5-1
				* AUC值=0.7，可理解為給定一個正樣本和負樣本，在70%情況下，模型正樣本的機率高於負樣本(?)
				* 此數值越大，模型效果越好
		* PRC曲線(Precision Recall Curve)
			* 橫坐標為precision，縱坐標為recall
		* ROC和PRC比較
			* 當正負樣本差距不大，趨勢差不多
			* 當負樣本很多，ROC比PRC好
